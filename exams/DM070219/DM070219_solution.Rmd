---
title: "Data Mining Test (Lab)"
date: "07/02/2019"
output:
  html_document: default
---

Name: 

Surname:

Badge number:


## EXERCIZE 1

a. 

```{r}
rm(list=ls())
data(longley)
fit = lm(GNP.deflator ~ ., longley)
X = model.matrix(fit)
p = ncol(X)
n = nrow(X)
y = longley$GNP.deflator
lambda <- 0.005
hatbeta <- solve(t(X) %*% X + lambda*diag(p)) %*% t(X) %*% y
print(hatbeta)
```

b.

```{r}
sigma2 = 1
W = solve(diag(p) + lambda*solve(t(X) %*% X))
Var = sigma2* diag( W%*% solve(t(X) %*% X) %*% t(W)  )
round(Var,4)
```


c. 

```{r}
LOOCV <- vector()
for (i in 1:n){
  X_i <- X[-i,]
  hatbeta_i = solve(t(X_i) %*% X_i + lambda*diag(1:p)) %*% t(X_i) %*% y[-i] 
  LOOCV[i] = ( X[i,] %*% hatbeta_i - y[i])^2
}
cat("LOOCV ridge: ", mean(LOOCV))

library(boot)
yX = data.frame(y,X)
fit.lm = glm(y ~ 0 + ., yX, family = gaussian) 
cat("LOOCV lm: ", cv.glm(yX, fit.lm)$delta[1])
```

Text answer.


## EXERCIZE 2

```{r}
rm(list=ls())
n=10
sigma=10
x = 1:n
fx = rep(1,n)
ds = 0:9
ps = ds+1
fun <- function(d) if (d==0) lm(fx~1) else lm(fx~poly(x,d))
Bias2s = sapply(ps, function(p)
  mean( ( fx - fitted(fun(d=p-1)) )^2 )
  )
Vars = ps*(sigma^2)/n
Errs = Bias2s + Vars + sigma^2
names(Errs) = paste("d =", ds)
Errs
```

## EXERCIZE 3

```{r}
set.seed(123)
n = 1000
p = 20
X = matrix(rnorm(p*n), ncol=p)
beta = c(2,rep(1,5),rep(0,15))
y = beta[1] + X%*%beta[-1] + rnorm(n)
combi = data.frame(y=y, X=X)
train = combi[1:100,]
test = combi[101:1000,]
library(leaps)
fit <- regsubsets(y ~ .,train, nvmax=20)
hatbeta = matrix(0, ncol=21, nrow=10)
where = summary(fit)$which
dk = vector()
for (k in 1:10){
 hatbeta[k,where[k,]] <- coef(fit,k)
 dk[k] <- sqrt( sum( (hatbeta[k,] - beta)^2 )  )
 }
plot(1:10,dk)
```

