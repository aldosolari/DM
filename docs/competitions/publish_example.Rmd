---
title: "DM competitions"
output: html_document
---

TEAM NAME: solari.aldo 

TEAM MEMBERS: Aldo Solari (solari.aldo) 

## Online dating

The goal is predict whether a person's profession is STEM or not. The area under the ROC curve (AUC) is used to evaluate models.  The training set includes 6000 profiles, of which 1095 are in the STEM fields. This implies a moderate class imbalance: 18.25% of profiles are STEM. The data contains different types of predictors:

* 1 numeric (`essay_length`), 3 integers (`height`,`age`,`last_online`), 17 factors, 87 dummies
* The number of levels of factors ranges from 51 (`where_town`) to 3 (`orientation`)
* Factors may have a "missing" level: e.g. `drinks` has the level `drinks_missing`
* It may happen that a predictor level is present in only the test set and not in the training set (or vice-versa), e.g. the level `vietnam` of the predictor `where_state` is present in only the test set

Given the large number of categorical predictors, we will consider classification trees (CART algorithm) because

* can handle numeric or categorical predictors
* can use a categorical predictior in its natural form (i.e., without conversions to dummy variables)
* can handle missing values by using surrugate splits
* perform intrinsic feature selection if a predictor is not used in any split of a tree
* inherently model interactions between predictors through subsequent recursive splits in the tree

For the final prediction, bagged CART decision trees will be used in order to stabilise trees. 

*Summary of the modelling process:*

1. *Preprocessing* <br>
None

2. *Missing values* <br>
Missing values occur only in factors. Because they are already encoded as a naturally occurring category (e.g. `drinks` has the level `drinks_missing`), we treat them as such

3. *Feature engineering* <br>
None
 
4. *Feature selection* <br>
Intrinsic feature selection by decision trees

5. *Final model* <br>
Bagged ($B=25$) decision trees with settings `minsplit=2`, `cp=0`, `xval=0` for the `rpart` algorithm 

6. *Model tuning and evaluation* <br>
None

7. *R packages* <br>
`ipred`

8. *References* <br>
The book [Feature Engineering and Selection](http://www.feat.engineering/index.html). In particular sections 5, 5.3 and 5.7 for encoding categorical predictors, sections 8.2 and 8.4 for handling missing data and section 10.2 for feature selection


```{r startup, include = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = T, eval=T, message=F, warning=F, error=F, comment=NA, cache=F, R.options=list(width=220))
```

**R code to reproduce the last submission**

```{r}
rm(list=ls())
library(ipred)
library(rpart)
training <- read.csv("http://bee-fore.s3-eu-west-1.amazonaws.com/datasets/112.csv")
test <- read.csv("http://bee-fore.s3-eu-west-1.amazonaws.com/datasets/113.csv")
n = nrow(training)
m = nrow(test)
test$Class = NA
combi = rbind(training,test)
training = combi[1:n,]
test = combi[(n+1):(n+m),]
set.seed(123)
fit <- bagging(Class ~ ., training, nbagg=25, control=rpart.control(minsplit=2, cp=0, xval=0))
phat = predict(fit, newdata=test, type="prob")[,"stem",drop=F]
head(phat)
sessionInfo()
```

## Miss Congeniality

Etc.
