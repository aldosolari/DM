---
title: "Data Mining"
subtitle: "Un semplice problema-tipo"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      ratio: '16:9'
      countIncrementalSlides: false
---

```{r startup, include = FALSE, message = FALSE, warning = FALSE, error=F, comment=NA}
knitr::opts_chunk$set(echo = T)
```


# Descrizione del problema

* Si consideri il seguente problema illustrativo che ci servirà da propototipo per situazioni più complesse e realistiche. 

* Ieri abbiamo raccolto $n$ $(n=30)$ coppie di osservazioni, i dati di addestramento (__training set__)
$$(x_1,y_1), (x_2,y_2), \ldots, (x_n,y_n)$$ 

* Domani osserveremo nuove $n=30$ coppie di osservazioni, i dati di verifica (__test set__)
$$(x_1,y^*_1), (x_2,y^*_2), \ldots, (x_n,y^*_n)$$

---


```{r}
library(readr)
df <- read_table2("http://azzalini.stat.unipd.it/Book-DM/yesterday.dat", col_types=cols())[-31,]
train <- data.frame(x=df$x, y=df$y.yesterday)
test <- data.frame(x=df$x, y=df$y.tomorrow)
plot( y ~ x , train)
```

---

* I dati in realtà sono stati generati artificialmente da una legge del tipo 
$$Y_i = f(x_i) + \varepsilon_i,\quad i=1,\ldots,n$$
dove $\varepsilon_1,\ldots,\varepsilon_n$ sono variabili casuali (v.c.) indipendenti e identicamente distribute (i.i.d.) $N(0,\sigma^2)$ con $\sigma=10^{-2}$, mentre $f$ è una funzione che lasceremo non specificata, salvo per il fatto che si tratta di una funzione dall'andamento sostanzialmente regolare. 
Naturalmente per poter generare i dati è stata scelta una funzione specifica (e non è un polinomio). Si noti che la v.c. viene indicata con $Y_i$, mentre la sua realizzazione (il valore osservato) con $y_i$. Inoltre si assume che $x_1,\ldots,x_n$ sono dei valori costanti (non casuali) fissati dallo sperimentatore. 

* Per semplicità di ragionamento assumiamo che queste nuove $y^*_i$ siano associate alle stesse ascisse $x_i$ dei dati di ieri. Abbiamo quindi che domani osserveremo $n$ coppie di dati $(x_i,y^*_i)$ per $i=1,\ldots,n$, i dati di verifica (*test set*) generati come
$$Y^*_{i}=f(x_i)+\varepsilon^*_i, \quad i=1,\ldots,n$$
dove $\varepsilon^*_1,\ldots,\varepsilon^*_n$ sono i.i.d. $N(0,\sigma^2)$ con $\sigma=10^{-2}$. 

* Le assunzioni fatte corrispondono al cosiddetto *Fixed-X setting*: 

    * i valori $x_1,\ldots,x_n$ del training set sono fissati (non casuali)

    * i valori di $x$ nel test set sono uguali ai valori di $x$ nel training set

* Approfondimento su Fixed-X e Random-X setting: [Rosset and Tibshirani (2018)](https://arxiv.org/pdf/1704.08160.pdf).

---

# Regressione polinomiale

* Si consideri un modello di regressione polinomiale di grado $d$:

$$f(x) = \beta_1 + \beta_2 x + \beta_3 x^2 + \ldots + \beta_{d+1} x^{d}$$

* E' quindi possibile utilizzare i dati di addestramento (training set) per ottenere le stime $\hat{\beta}_1,\hat{\beta}_2,\ldots$ e quindi
$$\hat{f}(x)=\hat{\beta}_1 + \hat{\beta}_2 x + \hat{\beta}_3 x^2 + \ldots + \hat{\beta}_{d+1} x^{d}$$ per predire le nuove $y_i^*$ che osserveremo domani utilizzando
$$\hat{y}_i^*=\hat{f}(x_i), \quad i=1,\ldots,n$$

* Non avendo informazioni che ci guidino nella scelta del grado del polinomio, possiamo considerare tutti i gradi possibili con $d$ tra $0$ e $n-1$, quindi con un numero $p=d+1$ di parametri che varia da $1$ a $n$, in aggiunta a $\sigma$.

---

# Dati ieri-domani

I dati sono disponibili all'indirizzo web http://azzalini.stat.unipd.it/Libro-DM/. In particolare:

* i dati "di ieri e di domani":  http://azzalini.stat.unipd.it/Libro-DM/ieri-domani.dat dove (`x`, `y.ieri`) sono i dati di training $(x_i,y_i)$ e (`x`, `y.domani`) sono i dati di test $(x_i,y^*_i)$

* i valori della vera funzione " $f$ "  (`f.vera`) in corrispondenza ai punti specificati (`x`) e il valore vero di $\sigma$ (`sqm.vero <- 0.01`): 
http://azzalini.stat.unipd.it/Libro-DM/f_vera.R

---

# Domanda 1

* Stimare il modello di regressione polinomiale di grado $d=3$ 

* Aggiungere al diagramma di dispersione di $(x_i,y_i)$, $i=1,\ldots,n$ i valori previsti dal modello. 

* Calcolare l'errore quadratico medio sui dati di training (*Training Mean Squared Error*)
$$\mathrm{MSE}_{\mathrm{Tr}} = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{f}(x_i))^2$$ 

* Per rispondere a questa domanda, potete utilizzare **solo** il training set, ovvero i dati `x` e `y.ieri`. 

---

# Soluzione 1

```{r}
d <- 3
fit <- lm(y ~ poly(x, degree=d, raw=T), train)
betahat <- coef(fit)
names(betahat) <- paste("hatbeta", 1:(d+1), sep="")
betahat
```

Dato un qualunque $x \in \mathbb{R}$, il modello prevede
$$\hat{y} = \hat{\beta}_1 + \hat{\beta}_2 x + \hat{\beta}_3 x^2 + \hat{\beta}_4 x^3$$
Nel seguito indicheremo con $\hat{y}_i$ i valori previsti per $x_i$, $i=1,\ldots,n$. 

---

Il seguente grafico rappresenta il diagramma di dispersione delle osservazioni del training set $(x_i,y_i)$ (pallini vuoti), e le mette a confronto con i valori previsti dal modello $(x_i,\hat{y}_i)$ (pallini pieni). 

```{r}
yhat <- fitted(fit)
plot(y ~ x, train)
points(yhat ~ x, train, pch=19)
lines(yhat ~ x, train, lwd=2)
```

---

Infine, $\mathrm{MSE}_{\mathrm{Tr}} = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2$ 

```{r}
MSE.tr <- mean((train$y - yhat)^2)
MSE.tr
```


---

# Domanda 2

* **Si decida il grado** $d$ da utilizzare per prevedere i dati di domani, con l'obiettivo di minimizzare l'errore di previsione, ovvero l'errore quadratico medio sui dati di test (*Test Mean Squared Error*)
$$\mathrm{MSE}_{\mathrm{Te}} = \frac{1}{n}\sum_{i=1}^{n}( y^*_i - \hat{f}(x_i))^2$$

* Si noti che $\mathrm{MSE}_{\mathrm{Te}}$ sarà calcolabile solo domani (ovvero dopo aver fatto le previsioni), a differenza dell'errore quadratico medio sui dati di training $\mathrm{MSE}_{\mathrm{Tr}}$, 
che si può calcolare già oggi avendo a disposizione i dati di ieri.

* Qual è il criterio (statistico) alla base della scelta effettuata?

---

# Notazione matriciale

La regressione polinomiale è un caso particolare del modello lineare (in notazione matriciale)
$$\mathbf{y} = \mathbf{X} \bf{\beta} + \bf{\varepsilon}$$
dove $\underset{n\times 1}{\mathbf{y}} = (y_1,\ldots,y_n)^\mathsf{T}$ è il vettore risposta di dimensione $n\times 1$, $\underset{p\times 1}{\beta} = (\beta_1,\ldots,\beta_p)^\mathsf{T}$ è il vettore dei coefficienti di dimensione $p \times 1$ e $\underset{n\times p}{\mathbf{X}}$ è la matrice del disegno di dimensione $n \times p$, ovvero

$$\underset{n\times 1}{\mathbf{y}} = 
\left[
\begin{array}{c}
y_1   \\
\cdots\\
y_i  \\
\cdots\\
y_n \\
\end{array}\right] \qquad
\underset{n\times p}{\mathbf{X}} = \left[
\begin{array}{cccccc}
x_{1}^\mathsf{T}   \\
x_{2}^\mathsf{T}  \\
\cdots   \\
x_{i}^\mathsf{T}    \\
\cdots\\
x_{n}^\mathsf{T}\\
\end{array}\right] = \left[
\begin{array}{cccccc}
x_{11}  & x_{12}  & \cdots   &  x_{1j}  & \cdots   &   x_{1p}  \\
x_{21}  & x_{22} & \cdots   &  x_{2j}  & \cdots   &   x_{2p}  \\
\cdots   & \cdots   &  \cdots & \cdots   &  \cdots  \\
x_{i1}  & x_{i2} & \cdots   &  x_{ij}& \cdots   & x_{ip}    \\
\cdots   & \cdots   &  \cdots  &  \cdots   &  \cdots\\
x_{n1}   & x_{n2} & \cdots   & x_{nj}    &  \cdots   &   x_{np}\\
\end{array}\right]$$

e infine $\underset{n\times 1}{\mathbf{\varepsilon}} = (\varepsilon_1,\ldots,\varepsilon_n) ^\mathsf{T}$ ha distribuzione Normale $n$-variata $N_n(\mathbf{0}, \sigma^2 \mathbf{I}_n)$ dove $\mathbf{I}_n$ indica la matrice identità con $n$ righe. 

---

# La matrice del disegno

```{r, echo=T}
fit <- lm( y ~ poly(x, degree=3, raw=TRUE), train)
X = model.matrix(fit)
colnames(X) = c("Intercept","x","x^2","x^3")
head(X)
```


La matrice del disegno del modello di regressione polinomiale di terzo grado ha dimensione $p=4$ perchè include l'intercetta $1$ e i termini $x,x^2,x^3$

---

# Polinomi ortogonali

```{r, echo=T}
fit <- lm( y ~ poly(x, degree=3, raw=FALSE), train)
X = model.matrix(fit)
colnames(X) = c("Intercept","x1","x2","x3")
round( t(X) %*% X, 8)
```

Per una spiegazione di come la funzione `poly` costruisce i polinomi ortogonali si veda [qui](https://stackoverflow.com/questions/39031172/how-poly-generates-orthogonal-polynomials-how-to-understand-the-coefs-ret/39051154#39051154)

---

Di conseguenza, se $\mathbf{X}^\mathsf{T}\mathbf{X} = \mathbf{I}_p$, si ottiene
$$\hat{\bf{\beta}} = (\mathbf{X}^\mathsf{T}\mathbf{X})^{-1}\mathbf{X}^\mathsf{T} \mathbf{y} = \mathbf{X}^\mathsf{T} \mathbf{y}$$

```{r}
stima_reg_poly <-
function(x, y, n=1L)
{
Z <- cbind(1/length(x), poly(x, n=n))
beta_hat <- crossprod(Z, y)
beta_hat
}
stima_reg_poly(train$x,train$y,n=3)
coef(lm(y ~ poly(x, degree=3), train))
```


---

# Regressione polinomiale di grado 24

```{r, echo=FALSE}
my_poly <- function (x, degree = 1) {
  if (length(unique(x)) < degree)
    stop("insufficient unique data points for specified degree!")
  centre <- mean(x)
  x <- x - centre
  QR <- qr(outer(x, 0:degree, "^"))
  X <- qr.qy(QR, diag(diag(QR$qr), length(x), degree + 1))[, -1, drop = FALSE]
  X2 <- X * X
  norm2 <- colSums(X * X)
  alpha <- drop(crossprod(X2, x)) / norm2
  beta <- norm2 / (c(length(x), norm2[-degree]))
  colnames(X) <- 1:degree
  scale <- sqrt(norm2)
  X <- X * rep(1 / scale, each = length(x))
  attr(X, "coefs") <- list(centre = centre, scale = scale, alpha = alpha[-degree], beta = beta[-degree])
  X
  }
my_predict_poly <- function (X, x) {
  ## extract construction info
  coefs <- attr(X, "coefs")
  centre <- coefs$centre
  alpha <- coefs$alpha
  beta <- coefs$beta
  degree <- ncol(X)
  ## centring `x`
  x <- x - coefs$centre
  ## repeat first polynomial `x` on all columns to initialize design matrix X
  X <- matrix(x, length(x), degree, dimnames = list(NULL, 1:degree))
  if (degree > 1L) {
    ## second polynomial
    X[, 2] <- (x - alpha[1]) * X[, 1] - beta[1]
    ## further polynomials obtained from recursion
    i <- 3
    while (i <= degree) {
      X[, i] <- (x - alpha[i - 1]) * X[, i - 1] - beta[i - 1] * X[, i - 2]
      i <- i + 1
      }
    }
  ## column rescaling so that `crossprod(X)` is an identity matrix
  X * rep(1 / coefs$scale, each = length(x))
  }
my_X = my_poly(train$x, degree = 24)
fit <- lm( y ~ my_X, train)
hatbeta = coef(fit)[-1]
new_x = seq(min(train$x), max(train$x), length.out = 2000)
new_X <- my_predict_poly(my_X,new_x)
yhat = coef(fit)[1] + new_X %*% hatbeta
plot(train$x,train$y)
lines(new_x, yhat)
```

---

# Domanda 3

* La stima del polinomio di grado $d=3$ si può ottiene con il seguente comando: 
```{r}
fit <- lm( y ~ poly(x, degree=3, raw=FALSE), train)
yhat <- predict(fit, newdata=test)
```

* Si noti che con `poly(x, degree=3, raw=TRUE)` si ottengono le stesse `yhat`. Perchè?

* **Cosa vi aspettate** di ottenere (in termini di valori previsti $\hat{y}^*_i$) se utilizzate il polinomio di grado $n-1$? Si giustifichi la risposta. 

---

# Domanda 4

* Si supponga di conoscere la vera $f$. **Si decida il grado** $d$ da utilizzare per prevedere generici dati di domani (non necessariamente il test set `x` e `y.domani`) con generici dati di ieri (non necessariamente il training set `x` e `y.ieri`), con l'obiettivo di minimizzare il valore atteso dell'errore di previsione, ovvero
$$\mathbb{E}[\mathrm{MSE}_{\mathrm{Te}}] = \frac{1}{n}\sum_{i=1}^{n}\mathbb{E}[( y^*_i - \hat{f}(x_i))^2]$$
dove il valore atteso è rispetto alle v.c. $Y_1,\ldots,Y_n$ e $Y^*_1,\ldots,Y^*_n$. 

* Si giustifichi la scelta effettuata, commentando il risultato con riferimento alla risposta fornita alla domanda 2.

* Lettura suggerita: Capitolo 7.2 del libro Hastie, Tibshirani, Friedman (2009). The Elements of Statistical Learning. Springer

* Per rispondere a questa domanda, potete utilizzare **solo** la vera $f$ e il vero valore di $\sigma$, ovvero i dati `f.vera`, `x` e `sqm.vero`. 

---

# Domanda 5

* Si supponga di conoscere la vera $f$ e di aver osservato i dati di ieri. **Si decida il grado** $d$ da utilizzare per prevedere generici dati di domani con i dati effettivamente osservati ieri (il training set `x` e `y.ieri`), con l'obiettivo di minimizzare il valore atteso dell'errore di previsione condizionato ai dati effettivamente osservati ieri, ovvero
$$\mathbb{E}(\mathrm{MSE}_{\mathrm{Te}} | Y_1=y_1,\ldots,Y_n=y_n)= \frac{1}{n}\sum_{i=1}^{n}\mathbb{E}\left[( Y^*_i - \hat{f}(x_i))^2 |  Y_1=y_1,\ldots,Y_n=y_n\right]$$
dove il valore atteso è rispetto alle v.c. $Y^*_1,\ldots,Y^*_n$. 

* Si giustifichi la scelta effettuata, commentando il risultato con riferimento alle risposte fornite alle domande 2. e 4.

* Per rispondere a questa domanda, potete utilizzare **solo** il training set, la vera $f$ e il vero valore di $\sigma$, ovvero i dati `x` e `y.ieri`,  `f.vera` e `sqm.vero`. 


