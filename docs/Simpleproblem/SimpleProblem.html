<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Data Mining</title>
    <meta charset="utf-8" />
    <meta name="author" content="Aldo Solari" />
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Data Mining
## Un semplice problema-tipo
### Aldo Solari

---





# Descrizione del problema

* Si consideri il seguente problema illustrativo che ci servirà da propototipo per situazioni più complesse e realistiche. 

* Ieri abbiamo raccolto `\(n\)` `\((n=30)\)` coppie di osservazioni, i dati di addestramento (__training set__)
`$$(x_1,y_1), (x_2,y_2), \ldots, (x_n,y_n)$$` 

* Domani osserveremo nuove `\(n=30\)` coppie di osservazioni, i dati di verifica (__test set__)
`$$(x_1,y^*_1), (x_2,y^*_2), \ldots, (x_n,y^*_n)$$`

---


```r
library(readr)
df &lt;- read_table2("http://azzalini.stat.unipd.it/Book-DM/yesterday.dat", col_types=cols())[-31,]
train &lt;- data.frame(x=df$x, y=df$y.yesterday)
test &lt;- data.frame(x=df$x, y=df$y.tomorrow)
plot( y ~ x , train)
```

![](SimpleProblem_files/figure-html/unnamed-chunk-1-1.png)&lt;!-- --&gt;

---

* I dati in realtà sono stati generati artificialmente da una legge del tipo 
`$$Y_i = f(x_i) + \varepsilon_i,\quad i=1,\ldots,n$$`
dove `\(\varepsilon_1,\ldots,\varepsilon_n\)` sono variabili casuali (v.c.) indipendenti e identicamente distribute (i.i.d.) `\(N(0,\sigma^2)\)` con `\(\sigma=10^{-2}\)`, mentre `\(f\)` è una funzione che lasceremo non specificata, salvo per il fatto che si tratta di una funzione dall'andamento sostanzialmente regolare. 
Naturalmente per poter generare i dati è stata scelta una funzione specifica (e non è un polinomio). Si noti che la v.c. viene indicata con `\(Y_i\)`, mentre la sua realizzazione (il valore osservato) con `\(y_i\)`. Inoltre si assume che `\(x_1,\ldots,x_n\)` sono dei valori costanti (non casuali) fissati dallo sperimentatore. 

* Per semplicità di ragionamento assumiamo che queste nuove `\(y^*_i\)` siano associate alle stesse ascisse `\(x_i\)` dei dati di ieri. Abbiamo quindi che domani osserveremo `\(n\)` coppie di dati `\((x_i,y^*_i)\)` per `\(i=1,\ldots,n\)`, i dati di verifica (*test set*) generati come
`$$Y^*_{i}=f(x_i)+\varepsilon^*_i, \quad i=1,\ldots,n$$`
dove `\(\varepsilon^*_1,\ldots,\varepsilon^*_n\)` sono i.i.d. `\(N(0,\sigma^2)\)` con `\(\sigma=10^{-2}\)`. 

* Le assunzioni fatte corrispondono al cosiddetto *Fixed-X setting*: 

    * i valori `\(x_1,\ldots,x_n\)` del training set sono fissati (non casuali)

    * i valori di `\(x\)` nel test set sono uguali ai valori di `\(x\)` nel training set

* Approfondimento su Fixed-X e Random-X setting: [Rosset and Tibshirani (2018)](https://arxiv.org/pdf/1704.08160.pdf).

---

# Regressione polinomiale

* Si consideri un modello di regressione polinomiale di grado `\(d\)`:

`$$f(x) = \beta_1 + \beta_2 x + \beta_3 x^2 + \ldots + \beta_{d+1} x^{d}$$`

* E' quindi possibile utilizzare i dati di addestramento (training set) per ottenere le stime `\(\hat{\beta}_1,\hat{\beta}_2,\ldots\)` e quindi
`$$\hat{f}(x)=\hat{\beta}_1 + \hat{\beta}_2 x + \hat{\beta}_3 x^2 + \ldots + \hat{\beta}_{d+1} x^{d}$$` per predire le nuove `\(y_i^*\)` che osserveremo domani utilizzando
`$$\hat{y}_i^*=\hat{f}(x_i), \quad i=1,\ldots,n$$`

* Non avendo informazioni che ci guidino nella scelta del grado del polinomio, possiamo considerare tutti i gradi possibili con `\(d\)` tra `\(0\)` e `\(n-1\)`, quindi con un numero `\(p=d+1\)` di parametri che varia da `\(1\)` a `\(n\)`, in aggiunta a `\(\sigma\)`.

---

# Dati ieri-domani

I dati sono disponibili all'indirizzo web http://azzalini.stat.unipd.it/Libro-DM/. In particolare:

* i dati "di ieri e di domani":  http://azzalini.stat.unipd.it/Libro-DM/ieri-domani.dat dove (`x`, `y.ieri`) sono i dati di training `\((x_i,y_i)\)` e (`x`, `y.domani`) sono i dati di test `\((x_i,y^*_i)\)`

* i valori della vera funzione " `\(f\)` "  (`f.vera`) in corrispondenza ai punti specificati (`x`) e il valore vero di `\(\sigma\)` (`sqm.vero &lt;- 0.01`): 
http://azzalini.stat.unipd.it/Libro-DM/f_vera.R

---

# Domanda 1

* Stimare il modello di regressione polinomiale di grado `\(d=3\)` 

* Aggiungere al diagramma di dispersione di `\((x_i,y_i)\)`, `\(i=1,\ldots,n\)` i valori previsti dal modello. 

* Calcolare l'errore quadratico medio sui dati di training (*Training Mean Squared Error*)
`$$\mathrm{MSE}_{\mathrm{Tr}} = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{f}(x_i))^2$$` 

* Per rispondere a questa domanda, potete utilizzare **solo** il training set, ovvero i dati `x` e `y.ieri`. 

---

# Soluzione 1


```r
d &lt;- 3
fit &lt;- lm(y ~ poly(x, degree=d, raw=T), train)
betahat &lt;- coef(fit)
names(betahat) &lt;- paste("hatbeta", 1:(d+1), sep="")
betahat
```

```
##    hatbeta1    hatbeta2    hatbeta3    hatbeta4 
##  0.29122183  0.47021547 -0.27641585  0.04852042
```

Dato un qualunque `\(x \in \mathbb{R}\)`, il modello prevede
`$$\hat{y} = \hat{\beta}_1 + \hat{\beta}_2 x + \hat{\beta}_3 x^2 + \hat{\beta}_4 x^3$$`
Nel seguito indicheremo con `\(\hat{y}_i\)` i valori previsti per `\(x_i\)`, `\(i=1,\ldots,n\)`. 

---

Il seguente grafico rappresenta il diagramma di dispersione delle osservazioni del training set `\((x_i,y_i)\)` (pallini vuoti), e le mette a confronto con i valori previsti dal modello `\((x_i,\hat{y}_i)\)` (pallini pieni). 


```r
yhat &lt;- fitted(fit)
plot(y ~ x, train)
points(yhat ~ x, train, pch=19)
lines(yhat ~ x, train, lwd=2)
```

![](SimpleProblem_files/figure-html/unnamed-chunk-3-1.png)&lt;!-- --&gt;

---

Infine, `\(\mathrm{MSE}_{\mathrm{Tr}} = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2\)` 


```r
MSE.tr &lt;- mean((train$y - yhat)^2)
MSE.tr
```

```
## [1] 0.0002085353
```


---

# Domanda 2

* **Si decida il grado** `\(d\)` da utilizzare per prevedere i dati di domani, con l'obiettivo di minimizzare l'errore di previsione, ovvero l'errore quadratico medio sui dati di test (*Test Mean Squared Error*)
`$$\mathrm{MSE}_{\mathrm{Te}} = \frac{1}{n}\sum_{i=1}^{n}( y^*_i - \hat{f}(x_i))^2$$`

* Si noti che `\(\mathrm{MSE}_{\mathrm{Te}}\)` sarà calcolabile solo domani (ovvero dopo aver fatto le previsioni), a differenza dell'errore quadratico medio sui dati di training `\(\mathrm{MSE}_{\mathrm{Tr}}\)`, 
che si può calcolare già oggi avendo a disposizione i dati di ieri.

* Qual è il criterio (statistico) alla base della scelta effettuata?

---

# Notazione matriciale

La regressione polinomiale è un caso particolare del modello lineare (in notazione matriciale)
`$$\mathbf{y} = \mathbf{X} \bf{\beta} + \bf{\varepsilon}$$`
dove `\(\underset{n\times 1}{\mathbf{y}} = (y_1,\ldots,y_n)^\mathsf{T}\)` è il vettore risposta di dimensione `\(n\times 1\)`, `\(\underset{p\times 1}{\beta} = (\beta_1,\ldots,\beta_p)^\mathsf{T}\)` è il vettore dei coefficienti di dimensione `\(p \times 1\)` e `\(\underset{n\times p}{\mathbf{X}}\)` è la matrice del disegno di dimensione `\(n \times p\)`, ovvero

`$$\underset{n\times 1}{\mathbf{y}} = 
\left[
\begin{array}{c}
y_1   \\
\cdots\\
y_i  \\
\cdots\\
y_n \\
\end{array}\right] \qquad
\underset{n\times p}{\mathbf{X}} = \left[
\begin{array}{cccccc}
x_{1}^\mathsf{T}   \\
x_{2}^\mathsf{T}  \\
\cdots   \\
x_{i}^\mathsf{T}    \\
\cdots\\
x_{n}^\mathsf{T}\\
\end{array}\right] = \left[
\begin{array}{cccccc}
x_{11}  &amp; x_{12}  &amp; \cdots   &amp;  x_{1j}  &amp; \cdots   &amp;   x_{1p}  \\
x_{21}  &amp; x_{22} &amp; \cdots   &amp;  x_{2j}  &amp; \cdots   &amp;   x_{2p}  \\
\cdots   &amp; \cdots   &amp;  \cdots &amp; \cdots   &amp;  \cdots  \\
x_{i1}  &amp; x_{i2} &amp; \cdots   &amp;  x_{ij}&amp; \cdots   &amp; x_{ip}    \\
\cdots   &amp; \cdots   &amp;  \cdots  &amp;  \cdots   &amp;  \cdots\\
x_{n1}   &amp; x_{n2} &amp; \cdots   &amp; x_{nj}    &amp;  \cdots   &amp;   x_{np}\\
\end{array}\right]$$`

e infine `\(\underset{n\times 1}{\mathbf{\varepsilon}} = (\varepsilon_1,\ldots,\varepsilon_n) ^\mathsf{T}\)` ha distribuzione Normale `\(n\)`-variata `\(N_n(\mathbf{0}, \sigma^2 \mathbf{I}_n)\)` dove `\(\mathbf{I}_n\)` indica la matrice identità con `\(n\)` righe. 

---

# La matrice del disegno


```r
fit &lt;- lm( y ~ poly(x, degree=3, raw=T), train)
X = model.matrix(fit)
colnames(X) = c("Intercept","x","x^2","x^3")
head(X)
```

```
##   Intercept         x       x^2       x^3
## 1         1 0.5000000 0.2500000 0.1250000
## 2         1 0.5862069 0.3436385 0.2014433
## 3         1 0.6724138 0.4521403 0.3040254
## 4         1 0.7586207 0.5755054 0.4365903
## 5         1 0.8448276 0.7137337 0.6029819
## 6         1 0.9310345 0.8668252 0.8070442
```


La matrice del disegno del modello di regressione polinomiale di terzo grado ha dimensione `\(p=4\)` perchè include l'intercetta `\(1\)` e i termini `\(x,x^2,x^3\)`

---

# Domanda 3

La stima del polinomio di grado `\(d=3\)` si ottiene con i seguenti comandi: 


```r
fit &lt;- lm( y ~ poly(x, degree=3), train)
yhat &lt;- predict(fit, newdata=test)
# si noti che con poly(x, degree=3, raw=TRUE) si ottengono le stesse yhat. Perchè?
```

tuttavia se provo con `\(d \geq 24\)` ottengo (almeno sul mio computer) il seguente messaggio di errore

```r
lm( y ~ poly(x, degree=24), train)
```
&gt; Error in poly(x, degree = 24) : 'degree' must be less than number of unique points

**Spiegare** qual è il problema. **Cosa vi aspettate** di ottenere (in termini di valori previsti `\(\hat{y}^*_i\)`) se utilizzate il polinomio di grado `\(n-1\)`? Si giustifichi la risposta. 


---

# Domanda 4

* Si supponga di conoscere la vera `\(f\)`. **Si decida il grado** `\(d\)` da utilizzare per prevedere generici dati di domani (non necessariamente il test set `x` e `y.domani`) con generici dati di ieri (non necessariamente il training set `x` e `y.ieri`), con l'obiettivo di minimizzare il valore atteso dell'errore di previsione, ovvero
`$$\mathbb{E}[\mathrm{MSE}_{\mathrm{Te}}] = \frac{1}{n}\sum_{i=1}^{n}\mathbb{E}[( y^*_i - \hat{f}(x_i))^2]$$`
dove il valore atteso è rispetto alle v.c. `\(Y_1,\ldots,Y_n\)` e `\(Y^*_1,\ldots,Y^*_n\)`. 

* Si giustifichi la scelta effettuata, commentando il risultato con riferimento alla risposta fornita alla domanda 2.

* Lettura suggerita: Capitolo 7.2 del libro Hastie, Tibshirani, Friedman (2009). The Elements of Statistical Learning. Springer

* Per rispondere a questa domanda, potete utilizzare **solo** la vera `\(f\)` e il vero valore di `\(\sigma\)`, ovvero i dati `f.vera`, `x` e `sqm.vero`. 

---

# Domanda 5

* Si supponga di conoscere la vera `\(f\)` e di aver osservato i dati di ieri. **Si decida il grado** `\(d\)` da utilizzare per prevedere generici dati di domani con i dati effettivamente osservati ieri (il training set `x` e `y.ieri`), con l'obiettivo di minimizzare il valore atteso dell'errore di previsione condizionato ai dati effettivamente osservati ieri, ovvero
`$$\mathbb{E}(\mathrm{MSE}_{\mathrm{Te}} | Y_1=y_1,\ldots,Y_n=y_n)= \frac{1}{n}\sum_{i=1}^{n}\mathbb{E}\left[( Y^*_i - \hat{f}(x_i))^2 |  Y_1=y_1,\ldots,Y_n=y_n\right]$$`
dove il valore atteso è rispetto alle v.c. `\(Y^*_1,\ldots,Y^*_n\)`. 

* Si giustifichi la scelta effettuata, commentando il risultato con riferimento alle risposte fornite alle domande 2. e 4.

* Per rispondere a questa domanda, potete utilizzare **solo** il training set, la vera `\(f\)` e il vero valore di `\(\sigma\)`, ovvero i dati `x` e `y.ieri`,  `f.vera` e `sqm.vero`.
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
