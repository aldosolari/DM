---
title: "Data Mining"
subtitle: "I dati Netflix"
author: Aldo Solari
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      ratio: '16:9'
      highlightLanguage: R
      countIncrementalSlides: false
      highlightLines: true   
---

```{r startup, include = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = T, eval=T, message=F, warning=F, error=F, comment=NA, cache=F)
```

# Sottomissione di prova su BeeViva

```{r, eval=F}
PATH <- "https://raw.githubusercontent.com/aldosolari/DM/master/docs/hw/"
X.tr = read.table(paste(PATH,"Train_ratings_all.dat", sep=""))
y.tr = read.table (paste(PATH,"Train_y_rating.dat", sep=""))
train = data.frame (X.tr, y=y.tr$V1)
X.te = read.table(paste(PATH,"Test_ratings_all.dat", sep=""))
test = data.frame (X.te)
fit = lm(y~.,data=train)
yhat = predict(fit, newdata=test)
write.table(file="mymissc.txt", yhat, row.names = FALSE, col.names = FALSE)
```

---

Carichiamo solo i dati di training (senza considerare le date)

```{r}
PATH <- "https://raw.githubusercontent.com/aldosolari/DM/master/docs/hw/"
X <- read.table(paste(PATH,"Train_ratings_all.dat", sep=""))
titles <- read.table(paste(PATH,"Movie_titles.txt", sep=""), sep=",")
names(X) <- substr(as.character(titles[,2]),1,20)
y <- read.table(paste(PATH,"Train_y_rating.dat", sep=""))
names(y) <- "y"
```

---

% di valori mancanti per film?

```{r}
barplot(sort(apply(X==0, 2, mean)), horiz=T, names.arg=F) 
```



---

Come è stato valutato il film Miss Congeniality?

.pull-left[
```{r}
table(y)
```
]

.pull-right[
```{r}
plot(table(y)/nrow(X))
```
]


---

Valutazione media rispetto ai film senza dati mancanti?

```{r}
sort(apply(data.frame(X[,1:14],y),2,mean))
```

---

Quali sono i film (senza dati mancanti) maggiormente correlati con Miss Congeniality?

```{r}
cor(X[,1:14],y)
```

---

Divisione in training e test

```{r}
m <- 2000
n <- nrow(X) - m
set.seed(123)
test.id <- sample(n+m,m)
test <- data.frame(y=y[test.id,], X[test.id,])
train <- data.frame(y=y[-test.id,], X[-test.id,])
```

Modello nullo

```{r}
yhat0 <- mean(train$y)
# RMSE.te
sqrt(mean((test$y-yhat0)^2))
```

---

Modello lineare (con i valori mancanti codificati = 0)

```{r}
fit1 <- lm(y ~ ., train)
# RMSE.tr
sqrt(mean((train$y-fitted(fit1))^2))
# RMSE.te
yhat1 <- predict(fit1, newdata=test)
sqrt(mean((test$y-yhat1)^2))
# un piccolo accorgimento
yhat2 <- pmin(yhat1,5)
sqrt(mean((test$y-yhat2)^2))
```

---

Modello lineare con i film senza dati mancanti

```{r, echo=T}
train14 <- train[,1:15]; fit3 <- lm(y ~ ., train14); summary(fit3)$coefficients
yhat3 <- predict(fit3, newdata=test); sqrt(mean((test$y-yhat3)^2))
```

---

# Regressione lineare multidimensionale

Si veda AS 2.1.3

Se ci sono $q$ variabili risposta $\underset{n \times q}{Y}$, e consideriamo $q$ modelli di regressione lineare usando la stessa matrice del disegno $\underset{n \times p}{X}$, arriviamo alla formulazione
$$\underset{n \times q}{Y} = \underset{n \times p}{X} \underset{p \times q}{B} + \underset{n \times q}{E}$$
dove $B$ è la matrice formata da $q$ colonne di dimensione $p$, ciascuna delle quali rappresenta i parametri di regressione per la corrispondente colonna di $Y$, e la matrice $E$ è costituita di termini di errore tali che
$$\mathbb{V}\mathrm{ar}(e_i) = \Sigma$$
dove $e_i^\mathsf{T}$ rappresenta la $i$-sima riga di $E$, per $i=1,\ldots,n$, e $\Sigma$ è la matrice di varianza/covarianza che esprime la correlazione delle variabili risposta. Allora la soluzione del problema dei minimi quadrati multidimensionali è 
$$\hat{B} = (X^\mathsf{T} X)^{-1}X^\mathsf{T} Y$$ 
che sono i $q$ vettori stimati per ciascuna variabile risposta, 
mentre la stima di $\Sigma$ è 
$\hat{\Sigma} = \frac{1}{n-p} Y^\mathsf{T}(I_n - H) Y$

---

Per i dati Neflix, la variabile risposta $Y\in \mathcal{Y}=\{1,2,3,4,5\}$. Sia 

$$Y_j = \left\{\begin{array}{cc}
1 & \mathrm{se\,\,} Y = j\\
0 & \mathrm{altrimenti}
\end{array}\right.$$

per $j\in \mathcal{Y}$. Otteniamo quindi una variabile risposta multidimensionale $\underset{n \times 5}{Y}$. 

Si noti che dal modello lineare per la $j$-ma variabile risposta $Y_j$ possiamo stimare $$f(x) = \mathbb{E}(Y_j|X=x) = \mathbb{P}(Y_j=1|X=x)$$
Possiamo inoltre stimare il valore atteso condizionato
$$\mathbb{E}(Y|X=x) = \sum_{j \in \mathcal{Y} } j \cdot \mathbb{P}(Y=j|X=x)$$
In questo caso il risultato coincide con quanto ottenuto dal modello lineare con risposta unidimensionale $Y$.

---

```{r}
q = 5
Y = matrix(0, nrow=n, ncol=q)
for (j in 1:q) Y[train$y==j,j]=1
X.tr = as.matrix(cbind(1,X[-test.id,]))
Bhat = solve(t(X.tr) %*% X.tr) %*% t(X.tr) %*% Y
X.te = as.matrix(cbind(1,X[test.id,]))
Yhat = X.te %*% Bhat
yhat3 <- (1:q)[apply(Yhat, 1, which.max)]
sqrt(mean((test$y-yhat3)^2))
yhat4 = Yhat %*% 1:q
sqrt(mean((test$y-yhat4)^2))
# si confronti yhat4 con yhat1
```




