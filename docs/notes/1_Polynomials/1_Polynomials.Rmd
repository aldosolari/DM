---
title: '**Polynomials**'
output:
  html_document:
    theme: cosmo
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

```{r startup, include = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = T, eval= T, message=F, warning=F, error=F, comment=NA, cache=T, R.options=list(width=220))
```

From Azzalini and Scarpa, Chapter 3

# A simple prototype problem

We consider here a very simple example serving as the prototype for much more complex and realistic circumstances. Let us presume that yesterday we observed $n = 30$ pairs of data, the __training set__
$$(x_1,y_1), (x_2,y_2), \ldots, (x_n,y_n)$$ 

```{r}
# import data from the web
library(readr)
df <- read_table2("http://azzalini.stat.unipd.it/Book-DM/yesterday.dat")[-31,]
# create training set
train <- data.frame(x=df$x, y=df$y.yesterday)
```

The data are shown in the scatterplot:

```{r}
plot( y ~ x , train)
```

The data were generated artificially by an equation such as

$$Y = f(X)+ \varepsilon$$

where $\varepsilon$ is an error component with distribution $N(0,\sigma^2)$ and $\sigma=0.01$; $f$ is a function which we leave unspecified, the only requirement is that this function should follow an essentially regular trend.
Clearly, to generate the data, we had to choose a specific function (not a polynomial), but we do not disclose our choice.

Say we wish to obtain an estimate $\hat{f}$ of $f$ today that allows us to predict $y$ as new observations of $x$ become available, i.e.
$$\hat{y} = \hat{f}(x)$$


Tomorrow data, or the __test set__, will be like
$$(x_1,y^*_1), (x_2,y^*_2), \ldots, (x_n,y^*_n)$$

Here the new observations 

* are $n$ as in the training set
* have new $y$ but old (train) $x$
* $x_1,\ldots,x_n$ are are treated as fixed, i.e. not random

This is a particular case which we will call __fixed-X setting__ .

In general the test set is of size $m$ and have both new $x$ and new $y$

$$(x^*_1,y^*_1), (x^*_2,y^*_2), \ldots, (x^*_m,y^*_m)$$

# Mean squared error

For the yesterday data (training data), we can compute the __mean squared error__ (MSE)
$$\mathrm{MSE}_{\mathrm{Tr}} = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{f}(x_i))^2$$ 


However, we would like to have a good performance on the test MSE
$$\mathrm{MSE}_{\mathrm{Te}} = \frac{1}{n}\sum_{i=1}^{n}( y^*_i - \hat{f}(x_i))^2$$ 

# Polynomial regression

A reasonable choice consists of using polynomial regression (of degree $d$)

$$f(x) = \beta_0 + \beta_1 x + \beta_2 x^2 + \ldots + \beta_d x^{d}$$

If we have no information to guide us in choosing the degree $d$ of the polynomial, we first consider all possible degrees from 0 to $n-1$, thereby introducing $p=d+1$ parameters ranging from $1$ to $n$, in addition to $\sigma$. 

Let's try a 3rd degree polynomial model ($d=3$)

```{r}
# create test set
test = data.frame(x=train$x, y=df$y.tomorrow)

# 3rd degree polynomial regression fit
fit <- lm( y ~ poly(x, degree=3), train)
yhat <- predict(fit, newdata=test)

# plot
plot( y ~ x , train)
lines( yhat ~ x, train)
```

Is this a good fit? We can compute $\mathrm{MSE}_{\mathrm{Tr}}$ for the 3rd degree polynomial model. 

```{r}
# compute MSE.tr for the 3rd degree polynomial fit
MSE.tr <- mean( (train$y - yhat)^2 )
MSE.tr
```

Now we compute $\mathrm{MSE}_{\mathrm{Tr}}$ for all possible degrees from 0 to $n-1$. 

```{r}
n <- nrow(train)
ds = 0:(n-1)
ps = ds + 1
# function to fit polynomial model of degree d
fun <- function(d) if (d==0) lm(y~1, train) else lm(y~poly(x,degree=d, raw=T), train)
fits <- sapply(ds, fun)

# compute MSE.tr for all degrees
MSEs.tr <- unlist( lapply(fits, deviance) )/n
plot(ps, MSEs.tr, type="b", xlab="p", ylab="MSE.tr")
```

The figure shows that the polynomial fit measured by $\mathrm{MSE}_{\mathrm{Tr}}$ seems to improve as $p$ increases.
A special case exists when $p = n$, corresponding to a polynomial that exactly interpolates the observed data, with $\mathrm{MSE}_{\mathrm{Tr}}=0$. 

# Overfitting

As already mentioned, we need to use an estimate of $f(x)$ to predict values of $y$ for new data $y^*_i,i=1,\ldots,n$ produced by the same generating mechanism, but these will become available tomorrow. 

We now evaluate the quality of the prediction using yesterday's fit of the polynomials for the new $y^*_i$, as if we could obtain tomorrow's data today. Let's try with the 20th degree polynomial:

```{r}
# 20th degree polynomial fit
fit <- lm( y ~ poly(x, degree=20), train)
yhat <- predict(fit, newdata=test)
# plots
op <- par(mfrow = c(1, 2))
plot( y ~ x , train)
lines(yhat ~ x, train)
plot( y ~ x , test, col=4)
lines(yhat ~ x, train)
par(op)
```

The figure shows yesterday and tomorrow's data with the predictions from the 20th degree polynomial. It is noteworthy that this high-degree polynomial fits very well the old points but fluctuate and no longer fit the new points. Here the model __overfits__ the training data.

Now we compute $\mathrm{MSE}_{\mathrm{Te}}$ for all possible degrees from 0 to $n-1$.

```{r}
# compute predictions for all degrees
yhats <- lapply(fits, predict)
# compute MSE.te for all degrees
MSEs.te <- unlist(lapply(yhats, 
           function(yhat) mean((test$y - yhat)^2)
           ))
# plot
plot(ps, MSEs.te, type="b", col=4, xlab="p", ylab="MSE.te")
# which p gives minimum MSE.te?
ps[which.min(MSEs.te)]
```

Here the $\mathrm{MSE}_{\mathrm{Te}}$ decreases to a certain point and
then increases.