---
title: '**Polynomials**'
output:
  html_document:
    theme: cosmo
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---

```{r startup, include = FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = T, eval= T, message=F, warning=F, error=F, comment=NA, cache=T, R.options=list(width=220))
```

From Azzalini and Scarpa, Chapter 3

# A simple prototype problem

We consider here a very simple example serving as the prototype for much more complex and realistic circumstances. Let us presume that yesterday we observed $n = 30$ pairs of data, the __training set__
$$(x_1,y_1), (x_2,y_2), \ldots, (x_n,y_n)$$
and that tomorrow we will observe $n = 30$ pairs of data, the __test set__
$$(x_1,y^*_1), (x_2,y^*_2), \ldots, (x_n,y^*_n)$$

Here we assume that  

* the training predictor values $x_1,\ldots,x_n$ are treated as fixed (i.e. non-random)
* the test predictor values $x_1,\ldots,x_n$ exactly match the the training predictor values $x_1,\ldots,x_n$

This setting is called __Fixed-X setting__. 

The responses in training data were generated artificially by 
$$Y_i = f(x_i)+ \varepsilon_i, \quad i=1,\ldots,n$$
and the responses in test data by
$$Y^*_{i}=f(x_i)+\varepsilon^*_i, \quad i=1,\ldots,n$$
where 

* $\varepsilon_1,\ldots,\varepsilon_n$ and $\varepsilon^*_1,\ldots,\varepsilon^*_n$ are i.i.d. $N(0,\sigma^2)$ with $\sigma=0.01$
* $f$ is a function which we leave unspecified, the only requirement is that this function should follow an essentially regular trend. Clearly, to generate the data, we had to choose a specific function (not a polynomial), but we do not disclose our choice.


Today we wish to obtain an estimate $\hat{f}$ of $f$ based on the training data that allows us to generate predictions for future tororrow data, i.e. 
$$\hat{y}^*_i = \hat{f}(x_i), \quad i=1,\ldots,n.$$

```{r}
# import data from the web
library(readr)
df <- read_table2("http://azzalini.stat.unipd.it/Book-DM/yesterday.dat")[-31,]
# create training set
train <- data.frame(x=df$x, y=df$y.yesterday)
```

The training data are shown in the scatterplot:

```{r}
plot( y ~ x , train)
```


# Mean squared error

For the yesterday data (training data), we can compute the __mean squared error__ (MSE)
$$\mathrm{MSE}_{\mathrm{Tr}} = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{f}(x_i))^2$$ 


However, we would like to have a good performance on the test MSE
$$\mathrm{MSE}_{\mathrm{Te}} = \frac{1}{n}\sum_{i=1}^{n}( y^*_i - \hat{f}(x_i))^2$$ 

# Polynomial regression

A reasonable choice consists of using polynomial regression (of degree $d$)
$$f(x) = \beta_0 + \beta_1 x + \beta_2 x^2 + \ldots + \beta_d x^{d}$$

If we have no information to guide us in choosing the degree $d$ of the polynomial, we first consider all possible degrees from 0 to $n-1$, thereby introducing $p=d+1$ parameters ranging from $1$ to $n$, in addition to $\sigma$. 

Let's try a 3rd degree polynomial model ($d=3$)

```{r}
# create test set
test = data.frame(x=train$x, y=df$y.tomorrow)

# 3rd degree polynomial regression fit
fit <- lm( y ~ poly(x, degree=3), train)
yhat <- predict(fit, newdata=test)

# plot
plot( y ~ x , train)
lines( yhat ~ x, train)
```

Is this a good fit? We can compute $\mathrm{MSE}_{\mathrm{Tr}}$ for the 3rd degree polynomial model. 

```{r}
# compute MSE.tr for the 3rd degree polynomial fit
MSE.tr <- mean( (train$y - yhat)^2 )
MSE.tr
```

Now we compute $\mathrm{MSE}_{\mathrm{Tr}}$ for all possible degrees from 0 to $n-1$. 

```{r}
n <- nrow(train)
ds = 0:(n-1)
ps = ds + 1
# function to fit polynomial model of degree d
fun <- function(d) if (d==0) lm(y~1, train) else lm(y~poly(x,degree=d, raw=T), train)
fits <- sapply(ds, fun)

# compute MSE.tr for all degrees
MSEs.tr <- unlist( lapply(fits, deviance) )/n
plot(ps, MSEs.tr, type="b", xlab="p", ylab="MSE.tr")
```

The figure shows that the polynomial fit measured by $\mathrm{MSE}_{\mathrm{Tr}}$ seems to improve as $p$ increases. A special case exists when $p = n$, corresponding to a polynomial that exactly interpolates the observed data, with $\mathrm{MSE}_{\mathrm{Tr}}=0$. 

# Overfitting

As already mentioned, we need to use an estimate $\hat{f}$ based on the training data to generate predictions for future, yet-to-be-seen data produced by the same generating mechanism. We now evaluate the quality of the prediction using yesterday's fit of the polynomials for the new $y^*_i$, as if we could obtain tomorrow's data today. Let's try with the 20th degree polynomial:

```{r}
# 20th degree polynomial fit
fit <- lm( y ~ poly(x, degree=20), train)
yhat <- predict(fit, newdata=test)
# plots
op <- par(mfrow = c(1, 2))
plot( y ~ x , train)
lines(yhat ~ x, train)
plot( y ~ x , test, col=4)
lines(yhat ~ x, train)
par(op)
```

The figure shows yesterday and tomorrow's data with the predictions from the 20th degree polynomial. It is noteworthy that this high-degree polynomial fits very well the old points but fluctuate and no longer fit the new points. Here the model __overfits__ the training data.

Now we compute $\mathrm{MSE}_{\mathrm{Te}}$ for all possible degrees from 0 to $n-1$.

```{r}
# compute predictions for all degrees
yhats <- lapply(fits, predict)
# compute MSE.te for all degrees
MSEs.te <- unlist(lapply(yhats, 
           function(yhat) mean((test$y - yhat)^2)
           ))
# plot
plot(ps, MSEs.te, type="b", col=4, xlab="p", ylab="MSE.te")
# which p gives minimum MSE.te?
ps[which.min(MSEs.te)]
```

Here the $\mathrm{MSE}_{\mathrm{Te}}$ decreases to a certain point and
then increases.